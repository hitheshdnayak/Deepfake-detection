{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"nYT-VgLLGfmG","executionInfo":{"status":"ok","timestamp":1697001919329,"user_tz":-330,"elapsed":6130,"user":{"displayName":"Abbu Bucker Siddique","userId":"15833761110828897326"}}},"outputs":[],"source":["import os\n","import numpy as np\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from sklearn.metrics import accuracy_score\n","from skimage.feature import hog\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import train_test_split\n","from skimage import io, color, restoration, transform, feature\n","import random\n"]},{"cell_type":"code","source":["# Check if GPU is available, else use CPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fIyrg7q_GkyU","executionInfo":{"status":"ok","timestamp":1697001919331,"user_tz":-330,"elapsed":23,"user":{"displayName":"Abbu Bucker Siddique","userId":"15833761110828897326"}},"outputId":"241a196a-8b9c-4941-daf0-0d2d99b5df1a"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"neo7huywGmrW","executionInfo":{"status":"ok","timestamp":1697001984545,"user_tz":-330,"elapsed":65229,"user":{"displayName":"Abbu Bucker Siddique","userId":"15833761110828897326"}},"outputId":"1058364e-2abc-4bc4-a3cd-90d7571c172b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["# Path to the folders containing real and fake images\n","real_images_path = \"/content/gdrive/MyDrive/celebdf/original-cropped-images\"\n","fake_images_path = \"/content/gdrive/MyDrive/celebdf/synthetic-cropped-images\"\n"],"metadata":{"id":"9zEhyfpQGqan","executionInfo":{"status":"ok","timestamp":1697002006459,"user_tz":-330,"elapsed":424,"user":{"displayName":"Abbu Bucker Siddique","userId":"15833761110828897326"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Function to load and preprocess images\n","# def load_and_preprocess_images(folder_path):\n","#     image_list = []\n","#     count =0\n","#     for filename in os.listdir(folder_path):\n","#         image = image.open(os.path.join(folder_path, filename))\n","#         image = image.resize((64, 64))  # Resize images to a consistent size\n","#         image = np.array(image)\n","#         image_list.append(image)\n","#         count+=1\n","#         print(f\"\\rProcessed {count} images\", end='')\n","#     return image_list\n","\n","def load_and_preprocess_images(folder):\n","    image_list = []\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    count=0\n","    for filename in os.listdir(folder):\n","        if filename.endswith(\".jpg\"):\n","            img_path = os.path.join(folder, filename)\n","            img = io.imread(img_path)\n","            img_gray = color.rgb2gray(img)\n","            img_resized = transform.resize(img_gray, (64, 64))  # Resize to a consistent size\n","\n","            # Convert the NumPy array to a PyTorch tensor\n","            img_tensor = torch.tensor(img_resized, dtype=torch.float32).to(device)\n","            image_list.append(img_tensor)\n","\n","            count+=1\n","            print(f\"\\rProcessed {count} images\", end='')\n","\n","    return image_list\n",""],"metadata":{"id":"nJVpWZlnGzsK","executionInfo":{"status":"ok","timestamp":1697002019306,"user_tz":-330,"elapsed":483,"user":{"displayName":"Abbu Bucker Siddique","userId":"15833761110828897326"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Load and preprocess real and fake images\n","real_images = load_and_preprocess_images(real_images_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bIfQeSbsJ31L","executionInfo":{"status":"ok","timestamp":1697002292995,"user_tz":-330,"elapsed":263682,"user":{"displayName":"Abbu Bucker Siddique","userId":"15833761110828897326"}},"outputId":"35fa67de-78df-4286-f5e7-f5e92b37ed9c"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Processed 8433 images"]}]},{"cell_type":"code","source":["fake_images = load_and_preprocess_images(fake_images_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7B_IWyEuKMkl","executionInfo":{"status":"ok","timestamp":1697002779384,"user_tz":-330,"elapsed":473142,"user":{"displayName":"Abbu Bucker Siddique","userId":"15833761110828897326"}},"outputId":"86cffa0f-0310-4f1b-b41d-6b64e466d610"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Processed 26317 images"]}]},{"cell_type":"code","source":["# # Create labels (0 for real, 1 for fake)\n","# real_labels = np.zeros(len(real_images))\n","# fake_labels = np.ones(len(fake_images))\n","\n","# Create labels (0 for real, 1 for fake)\n","real_labels_tensor = torch.zeros(len(real_images), dtype=torch.float32).to(device)\n","fake_labels_tensor = torch.ones(len(fake_images), dtype=torch.float32).to(device)\n","\n","real_images_tensor = torch.stack(real_images)\n","fake_images_tensor = torch.stack(fake_images)\n","\n","# Combine real and fake data\n","all_images = torch.cat((real_images_tensor, fake_images_tensor), dim=0)\n","all_labels = torch.cat((real_labels_tensor, fake_labels_tensor), dim=0)\n","\n","all_images_numpy = all_images.cpu().numpy()\n","all_labels_numpy = all_labels.cpu().numpy()\n","\n","\n","# # Combine real and fake images and labels\n","# X = np.concatenate((real_images, fake_images))\n","# y = np.concatenate((real_labels, fake_labels))\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(all_images_numpy, all_labels_numpy, test_size=0.2, random_state=42)\n"],"metadata":{"id":"eAZ2UNAKJ7nq","executionInfo":{"status":"ok","timestamp":1697002835785,"user_tz":-330,"elapsed":1423,"user":{"displayName":"Abbu Bucker Siddique","userId":"15833761110828897326"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Convert the NumPy arrays back to PyTorch tensors (and move to GPU if available)\n","X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n","X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n","y_train = torch.tensor(y_train, dtype=torch.float32).to(device)\n","y_test = torch.tensor(y_test, dtype=torch.float32).to(device)\n"],"metadata":{"id":"k9Hhzzi2Of5d","executionInfo":{"status":"ok","timestamp":1697002840957,"user_tz":-330,"elapsed":543,"user":{"displayName":"Abbu Bucker Siddique","userId":"15833761110828897326"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Function to extract HOG features from a list of images\n","def extract_hog_features(images):\n","    hog_features = []\n","    for image in images:\n","        hog_feature = hog(image, pixels_per_cell=(8, 8), cells_per_block=(2, 2))\n","        hog_features.append(hog_feature)\n","    return np.array(hog_features)\n"],"metadata":{"id":"n2PWBLePRY6C","executionInfo":{"status":"ok","timestamp":1697002850639,"user_tz":-330,"elapsed":757,"user":{"displayName":"Abbu Bucker Siddique","userId":"15833761110828897326"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["from skimage.feature import hog\n","from sklearn.preprocessing import StandardScaler\n","\n","# Move tensors to CPU\n","X_train_cpu = X_train.cpu().numpy()\n","X_test_cpu = X_test.cpu().numpy()\n","\n","# Extract HOG features from training and testing data\n","X_train_hog = extract_hog_features(X_train_cpu)\n","X_test_hog = extract_hog_features(X_test_cpu)\n","\n","# Standardize the HOG features\n","scaler = StandardScaler()\n","X_train_hog = scaler.fit_transform(X_train_hog)\n","X_test_hog = scaler.transform(X_test_hog)\n"],"metadata":{"id":"JKiNQfyjRUI4","executionInfo":{"status":"ok","timestamp":1697002918120,"user_tz":-330,"elapsed":64288,"user":{"displayName":"Abbu Bucker Siddique","userId":"15833761110828897326"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Convert HOG features to PyTorch tensors\n","X_train_hog_tensor = torch.tensor(X_train_hog, dtype=torch.float32)\n","X_test_hog_tensor = torch.tensor(X_test_hog, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n","y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n","\n","# Move tensors to CPU\n","X_train_hog_tensor = X_train_hog_tensor.cpu()\n","X_test_hog_tensor = X_test_hog_tensor.cpu()\n","y_train_tensor = y_train_tensor.cpu()\n","y_test_tensor = y_test_tensor.cpu()\n","\n","# Convert to NumPy arrays\n","X_train_hog = X_train_hog_tensor.numpy()\n","X_test_hog = X_test_hog_tensor.numpy()\n","y_train = y_train_tensor.numpy()\n","y_test = y_test_tensor.numpy()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NCuLnccdQ3_3","executionInfo":{"status":"ok","timestamp":1697002918122,"user_tz":-330,"elapsed":39,"user":{"displayName":"Abbu Bucker Siddique","userId":"15833761110828897326"}},"outputId":"56b229dd-1611-4d57-9ced-549348f07ee4"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-12-5b5ca016d14e>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n","<ipython-input-12-5b5ca016d14e>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n"]}]},{"cell_type":"code","source":["# Create a simple neural network\n","class NeuralNetwork(torch.nn.Module):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.fc1 = torch.nn.Linear(X_train_hog.shape[1], 128)\n","        self.relu = torch.nn.ReLU()\n","        self.fc2 = torch.nn.Linear(128, 1)\n","        self.sigmoid = torch.nn.Sigmoid()\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        x = self.sigmoid(x)\n","        return x\n","\n","# Initialize the model and define loss function and optimizer\n","model = NeuralNetwork()\n","criterion = torch.nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n"],"metadata":{"id":"lC4wQcawR0Sz","executionInfo":{"status":"ok","timestamp":1697002928372,"user_tz":-330,"elapsed":772,"user":{"displayName":"Abbu Bucker Siddique","userId":"15833761110828897326"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    optimizer.zero_grad()\n","    outputs = model(torch.tensor(X_train_hog, dtype=torch.float32))\n","    loss = criterion(outputs, torch.tensor(y_train, dtype=torch.float32).view(-1, 1))\n","    loss.backward()\n","    optimizer.step()\n","    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QMVA9F22R40B","executionInfo":{"status":"ok","timestamp":1697002941463,"user_tz":-330,"elapsed":7389,"user":{"displayName":"Abbu Bucker Siddique","userId":"15833761110828897326"}},"outputId":"0b30f32d-75a0-47d8-d31d-9870212b6a09"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/10], Loss: 0.7184\n","Epoch [2/10], Loss: 0.5977\n","Epoch [3/10], Loss: 0.5246\n","Epoch [4/10], Loss: 0.4726\n","Epoch [5/10], Loss: 0.4375\n","Epoch [6/10], Loss: 0.4170\n","Epoch [7/10], Loss: 0.4064\n","Epoch [8/10], Loss: 0.4005\n","Epoch [9/10], Loss: 0.3952\n","Epoch [10/10], Loss: 0.3888\n"]}]},{"cell_type":"code","source":["# Evaluate the model on the test set\n","with torch.no_grad():\n","    outputs = model(torch.tensor(X_test_hog, dtype=torch.float32))\n","    predicted = (outputs >= 0.5).squeeze().cpu().numpy()\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, predicted)\n","print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ntAVKAyHR8NV","executionInfo":{"status":"ok","timestamp":1697002950506,"user_tz":-330,"elapsed":670,"user":{"displayName":"Abbu Bucker Siddique","userId":"15833761110828897326"}},"outputId":"670343d5-31ed-4156-adc5-4e06aac754bf"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 82.22%\n"]}]},{"cell_type":"code","source":["pip install torchviz\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lhozMDNuQvyB","executionInfo":{"status":"ok","timestamp":1697003033599,"user_tz":-330,"elapsed":6748,"user":{"displayName":"Abbu Bucker Siddique","userId":"15833761110828897326"}},"outputId":"cd913944-8052-44a0-8101-494d4cec7166"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchviz\n","  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.0.1+cu118)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchviz) (3.27.6)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchviz) (17.0.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz) (1.3.0)\n","Building wheels for collected packages: torchviz\n","  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4130 sha256=6c823014ee04bf4438723de28f19f4e5737ae83df927656b6b0c0bc65d1d3e42\n","  Stored in directory: /root/.cache/pip/wheels/4c/97/88/a02973217949e0db0c9f4346d154085f4725f99c4f15a87094\n","Successfully built torchviz\n","Installing collected packages: torchviz\n","Successfully installed torchviz-0.0.2\n"]}]},{"cell_type":"code","source":["import torchviz\n","\n","# Create a sample input tensor with the correct shape\n","input_tensor = torch.randn(1, 1764)\n","\n","# Pass the input tensor to the model to generate the architecture\n","dot = torchviz.make_dot(model(input_tensor))\n","\n","# Render and save the model architecture\n","dot.render(\"model_architecture.png\", format=\"png\")\n","\n"],"metadata":{"id":"Hd_iv5X1R_dO","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1697003626232,"user_tz":-330,"elapsed":623,"user":{"displayName":"Abbu Bucker Siddique","userId":"15833761110828897326"}},"outputId":"afd2e5bb-abf0-494d-fe50-12b0562cf81b"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'model_architecture.png.png'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":19}]}]}